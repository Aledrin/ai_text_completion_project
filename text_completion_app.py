# -*- coding: utf-8 -*-
"""text_completion_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16hOpn8d7t6TyUB7o1raDZiG9mfJmRA_t
"""

import requests
from getpass import getpass

API_URL = "https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta"

def get_token():
    token = getpass("Enter your Hugging Face API Token: ").strip()
    while not token:
        print("API token cannot be empty. Please try again.")
        token = getpass("Enter your Hugging Face API Token: ").strip()
    return token

def query_hf(prompt, headers, temperature=0.7, max_new_tokens=50, top_p=0.9):
    if not prompt.strip():
        return "Error: Prompt cannot be empty."
    if len(prompt) > 1000:
        return "Error: Prompt is too long (max 1000 characters)."

    payload = {
        "inputs": prompt,
        "parameters": {
            "temperature": temperature,
            "max_new_tokens": max_new_tokens,
            "top_p": top_p
        }
    }

    try:
        response = requests.post(API_URL, headers=headers, json=payload, timeout=15)
    except requests.exceptions.Timeout:
        return "Error: Request timed out. Try again."
    except requests.exceptions.RequestException as e:
        return f"Error: Network problem occurred: {e}"

    if response.status_code == 200:
        try:
            output = response.json()
            if isinstance(output, dict) and "generated_text" in output:
                return output["generated_text"]
            elif isinstance(output, str):
                return output
            elif isinstance(output, list) and len(output) > 0 and "generated_text" in output[0]:
                return output[0]["generated_text"]
            else:
                return str(output)
        except Exception as e:
            return f"Error processing response JSON: {e}"
    elif response.status_code == 401:
        return "Error: Unauthorized. Check your API token."
    else:
        return f"Error {response.status_code}: {response.text}"

def get_float_input(prompt, default, min_val=None, max_val=None):
    while True:
        val = input(f"{prompt} [{default}]: ").strip()
        if not val:
            return default
        try:
            f = float(val)
            if (min_val is not None and f < min_val) or (max_val is not None and f > max_val):
                print(f"Value must be between {min_val} and {max_val}.")
                continue
            return f
        except ValueError:
            print("Invalid input. Please enter a number.")

def get_int_input(prompt, default, min_val=None, max_val=None):
    while True:
        val = input(f"{prompt} [{default}]: ").strip()
        if not val:
            return default
        try:
            i = int(val)
            if (min_val is not None and i < min_val) or (max_val is not None and i > max_val):
                print(f"Value must be between {min_val} and {max_val}.")
                continue
            return i
        except ValueError:
            print("Invalid input. Please enter an integer.")

def main():
    print("Text Completion App with Hugging Face Inference API")
    print("You can type 'quit' at any prompt to exit.\n")

    token = get_token()
    headers = {"Authorization": f"Bearer {token}"}

    while True:
        prompt = input("Enter your prompt: ").strip()
        if prompt.lower() in ['quit', 'exit', 'stop']:
            print("Session ended. Goodbye!")
            break

        temperature = get_float_input("Set temperature (creativity, 0.0-1.0)", 0.7, 0.0, 1.0)
        max_new_tokens = get_int_input("Set max new tokens (response length)", 50, 1, 200)
        top_p = get_float_input("Set top_p (nucleus sampling, 0.0-1.0)", 0.9, 0.0, 1.0)

        print("\nGenerating response...\n")
        response = query_hf(prompt, headers, temperature, max_new_tokens, top_p)
        print("AI Response:\n" + response + "\n")

if __name__ == "__main__":
    main()